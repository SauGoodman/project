import json
import logging
import awswrangler as wr
import requests
import pandas as pd
from botocore.exceptions import ClientError

# ログ設定の初期化
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    try:
        # ステップ1: S3からCSVファイルを文字列型で読み込む
        bucket_name = "mastergpoc"
        input_file_key = "temp/01_product_compare.csv"  # 入力ファイルのS3パス
        post_file_key = "results/01_product_apipost.csv"  # POST用結果ファイルのS3パス
        put_file_key = "results/01_product_apiput.csv"  # PUT用結果ファイルのS3パス

        logger.info(f"S3からCSVファイルを文字列型で読み込み中: s3://{bucket_name}/{input_file_key}")

        # CSVファイルの読み込み時にすべての列を文字列型に設定
        try:
            data = wr.s3.read_csv(
                f's3://{bucket_name}/{input_file_key}',
                dtype=str,  # 全列を文字列型で読み込む
                keep_default_na=False  # 空白セルをNaNではなく空文字列として扱う
            )
        except ClientError as e:
            logger.error(f"S3ファイルの読み込みに失敗しました: {str(e)}")
            return {"statusCode": 500, "body": f"S3ファイルの読み込みに失敗しました: {str(e)}"}

        logger.info(f"データの型確認: {data.dtypes}")
        logger.info(f"読み込んだデータの先頭行: {data[['buturyu_cd']].head()}")

        # ステップ2: APIトークンとヘッダーの設定
        token = "Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiI3NSIs..."
        headers = {
            "User-Agent": "test-agent",
            "Authorization": token,
            "ClientId": "75"
        }

        # ステップ3: APIリクエストの送信 (逐行)
        post_df_list = []
        put_df_list = []

        for index, row in data.iterrows():
            buturyu_cd = row['buturyu_cd']

            # 构建API请求URL
            api_url = f"https://api.plapi-product.com/plapi/api/v1/com_product_id/catalogs/{buturyu_cd}"
            logger.info(f"APIリクエスト送信中: {api_url}")

            try:
                response = requests.get(api_url, headers=headers, timeout=10)
                if response.status_code not in [200, 400]:
                    logger.error(f"APIリクエスト失敗: {response.status_code} - {response.text}")
                    continue

                # レスポンス解析
                try:
                    api_data = response.json()
                except json.JSONDecodeError:
                    logger.error(f"APIレスポンスのデコードに失敗しました: {response.text}")
                    continue

                errors = api_data.get("errors", [])
                templates = api_data.get("templates", [])

                # POST と PUT のデータ分割
                error_ids = {str(error["com_product_id"]) for error in errors}
                template_dict = {str(template["com_product_id"]): template["product_id"] for template in templates}

                # POSTデータフレーム作成
                if str(buturyu_cd) in error_ids:
                    post_df_list.append(row)

                # PUTデータフレーム作成
                if str(buturyu_cd) in template_dict:
                    row['product_id'] = template_dict[str(buturyu_cd)]
                    put_df_list.append(row)

            except requests.exceptions.Timeout:
                logger.error(f"APIリクエストがタイムアウトしました: {buturyu_cd}")
                continue
            except Exception as e:
                logger.error(f"APIリクエスト中にエラーが発生しました: {str(e)}")
                continue

        # 結果の結合
        post_df = pd.DataFrame(post_df_list)
        put_df = pd.DataFrame(put_df_list)

        # ステップ4: S3に保存
        if not post_df.empty:
            wr.s3.to_csv(post_df, f's3://{bucket_name}/{post_file_key}', index=False)
            logger.info(f"POST結果を保存しました: s3://{bucket_name}/{post_file_key}")

        if not put_df.empty:
            wr.s3.to_csv(put_df, f's3://{bucket_name}/{put_file_key}', index=False)
            logger.info(f"PUT結果を保存しました: s3://{bucket_name}/{put_file_key}")

        logger.info("処理が正常に完了しました。")
        return {"statusCode": 200, "body": json.dumps("処理が正常に完了しました。")}

    except Exception as e:
        logger.error(f"エラーが発生しました: {str(e)}")
        return {"statusCode": 500, "body": f"エラー: {str(e)}"}