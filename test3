import json
import logging
import awswrangler as wr
import requests
import pandas as pd
import boto3
from botocore.exceptions import ClientError
from time import sleep

# --- ログ設定 ---
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# --- DynamoDB 設定 ---
dynamodb = boto3.resource('dynamodb')
table_name = "RequestCount"
request_count_table = dynamodb.Table(table_name)

# --- API設定 ---
API_URL = "https://api.plapi-product.com/plapi/api/v1/products"
TOKEN = "Bearer <YOUR_API_TOKEN>"  # API トークンを設定
HEADERS = {
    "User-Agent": "test-agent",
    "Authorization": TOKEN,
    "ClientId": "75"
}

BATCH_SIZE = 100  # バッチサイズ

# --- DynamoDB 操作 ---
def get_last_processed_count(method_type):
    """DynamoDBから処理済み件数を取得"""
    try:
        response = request_count_table.get_item(Key={"FunctionType": method_type})
        return int(response['Item']['RecCount']) if 'Item' in response else 0
    except Exception as e:
        logger.error(f"DynamoDB取得エラー: {e}")
        return 0

def update_request_count(method_type, count):
    """DynamoDBに処理件数を更新"""
    try:
        request_count_table.update_item(
            Key={"FunctionType": method_type},
            UpdateExpression="SET RecCount = :count",
            ExpressionAttributeValues={":count": count}
        )
    except Exception as e:
        logger.error(f"DynamoDB更新エラー: {e}")

# --- POSTデータを処理 ---
def process_post_data(post_df, put_file_path):
    """POSTデータを処理し、PUT用データを保存"""
    response_list = []
    for i in range(0, len(post_df), BATCH_SIZE):
        batch_df = post_df.iloc[i:i + BATCH_SIZE]
        payload = {
            "products": [
                {
                    "category_id": row.get("category_id", "default"),
                    "product_name": row.get("product_name", "default"),
                    "product_status": "1"
                }
                for _, row in batch_df.iterrows()
            ]
        }
        try:
            response = requests.post(API_URL, headers=HEADERS, json=payload)
            if response.status_code == 200:
                logger.info(f"POST成功: {response.json()}")
                response_list.append(response.json())
            else:
                logger.error(f"POST失敗: {response.status_code}, {response.text}")
        except Exception as e:
            logger.error(f"POSTエラー: {e}")
        sleep(1)
    
    # 保存 PUT データ
    save_post_response_to_put_file(post_df, response_list, put_file_path)

def save_post_response_to_put_file(post_df, response_list, put_file_path):
    """POSTのレスポンスからProductIdを抽出し、PUTデータファイルを生成"""
    put_data = []
    for i, response in enumerate(response_list):
        if response and 'products' in response:
            for product in response['products']:
                put_data.append({
                    "product_id": product.get("product_id"),
                    "category_id": post_df.iloc[i]["category_id"],
                    "product_name": post_df.iloc[i]["product_name"],
                    "product_status": "1"
                })
    # CSVとして保存
    put_df = pd.DataFrame(put_data)
    put_df.to_csv(put_file_path, index=False)
    logger.info(f"PUTデータファイルが作成されました: {put_file_path}")

# --- Lambdaハンドラー ---
def lambda_handler(event, context):
    bucket_name = "mastergpoc"
    input_file_key_post = "results/01_product_apipost.csv"
    output_file_key_put = "/tmp/01_product_apiput.csv"
    s3_output_key_put = "results/01_product_apiput.csv"

    try:
        # --- POST処理 ---
        logger.info(f"S3読み込み: {bucket_name}/{input_file_key_post}")
        df_post = wr.s3.read_csv(f"s3://{bucket_name}/{input_file_key_post}", dtype=str)

        # DynamoDB から進捗取得
        last_post_count = get_last_processed_count("post")
        post_df = df_post.iloc[last_post_count:]
        if not post_df.empty:
            logger.info(f"POST処理データ: {len(post_df)} 件")
            process_post_data(post_df, output_file_key_put)
            update_request_count("post", last_post_count + len(post_df))

        # PUT用データをS3にアップロード
        wr.s3.upload(local_file=output_file_key_put, path=f"s3://{bucket_name}/{s3_output_key_put}")
        logger.info(f"PUTデータファイルがS3にアップロードされました: {s3_output_key_put}")

        return {"statusCode": 200, "body": "POST処理が完了し、PUTデータが準備されました"}

    except Exception as e:
        logger.error(f"エラーが発生しました: {e}")
        return {"statusCode": 500, "body": f"エラー: {e}"}