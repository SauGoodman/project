import json
import logging
import awswrangler as wr
import requests
import pandas as pd
from botocore.exceptions import ClientError

# Initialize logger
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    try:
        # Define S3 bucket and file paths
        bucket_name = "mastergpoc"
        input_file_key = "temp/01_product_compare.csv"
        post_file_key = "results/01_product_apipost.csv"
        put_file_key = "results/01_product_apiput.csv"

        logger.info(f"Reading file from S3: s3://{bucket_name}/{input_file_key}")

        # Read CSV from S3
        try:
            data = wr.s3.read_csv(f's3://{bucket_name}/{input_file_key}')
        except ClientError as e:
            logger.error(f"Failed to read S3 file: {str(e)}")
            return {"statusCode": 500, "body": f"Failed to read S3 file: {str(e)}"}

        # Prepare API URL
        buturyu_cd_list = data['buturyu_cd'].tolist()
        joined_buturyu_cd = "&".join(map(str, buturyu_cd_list))
        api_url = f"https://api.plapi-product.com/plapi/api/v1/com_product_id/catalogs?{joined_buturyu_cd}"
        logger.info(f"Generated API URL: {api_url}")

        # Set token and headers
        token = "Bearer <YOUR_TOKEN_HERE>"
        headers = {
            "User-Agent": "test-agent",
            "Authorization": token,
            "ClientId": "75"
        }

        # Make API request
        logger.info("Sending API request...")
        response = requests.get(api_url, headers=headers)
        if response.status_code not in [200, 400]:
            logger.error(f"API request failed: {response.status_code} - {response.text}")
            return {"statusCode": response.status_code, "body": f"API request failed: {response.text}"}

        # Parse API response
        try:
            api_data = response.json()
        except json.JSONDecodeError:
            logger.error(f"Failed to decode API response: {response.text}")
            return {"statusCode": 500, "body": "Failed to decode API response."}

        logger.info(f"API response received: {api_data}")

        # Process API response
        errors = api_data.get("errors", [])
        templates = api_data.get("templates", [])

        error_ids = {str(error["com_product_id"]) for error in errors}
        template_dict = {str(template["com_product_id"]): template["product_id"] for template in templates}

        # Split data into POST and PUT dataframes
        post_df = data[data["buturyu_cd"].isin(error_ids)]
        put_df = data[data["buturyu_cd"].isin(template_dict.keys())]

        # Update product_id in PUT DataFrame
        put_df["product_id"] = put_df["buturyu_cd"].map(template_dict)
        put_df = put_df[["product_id"] + list(data.columns)]

        # Write results back to S3
        if not post_df.empty:
            wr.s3.to_csv(post_df, f's3://{bucket_name}/{post_file_key}', index=False)
            logger.info(f"POST results saved: s3://{bucket_name}/{post_file_key}")

        if not put_df.empty:
            wr.s3.to_csv(put_df, f's3://{bucket_name}/{put_file_key}', index=False)
            logger.info(f"PUT results saved: s3://{bucket_name}/{put_file_key}")

        logger.info("Process completed successfully.")
        return {"statusCode": 200, "body": json.dumps("Process completed successfully.")}

    except Exception as e:
        logger.error(f"An error occurred: {str(e)}")
        return {"statusCode": 500, "body": f"Error: {str(e)}"}